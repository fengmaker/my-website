这是一次非常精彩的转向。既然我们要攻克工业界的问题，**启发式算法 (Heuristics)** 才是真正的战场。

如果说精确算法（Concorde, Branch-and-Price）是在**“追求完美的数学真理”**，那么启发式算法（尤其是 LKH 系列）就是在**“挑战人类工程直觉的极限”**。

我们将这段历史分为四个纪元，见证算法如何从“贪婪”走向“智慧”，最终诞生了统治该领域 20 年的霸主——**LKH-3**。

---

# 运筹学启发式算法专题：从 2-opt 到 LKH-3 的进化史

## 第一阶段：蛮荒时代 —— 局部搜索与 $k$-opt

**(The Era of Local Search)**

最早期的思路非常朴素：先随便找条路，然后修修补补。

### 1.1 构造法 (Construction)

比如 **最近邻法 (Nearest Neighbor)**：从 A 出发，每次去最近的没去过的城市。

- **结局**：贪得无厌，鼠目寸光。通常比最优解差 20% 以上，工业界基本不用。
    

### 1.2 邻域搜索 ($k$-opt)

这是现代启发式算法的基石。Croes (1958) 和 Lin (1965) 提出了核心思想：**交换 (Swap)**。

- **2-opt**：切断两条边，把中间的一段路径**翻转 (Reverse)**，再接回去。
    
    - _逻辑_：消除路径中的“交叉”。如果两条路交叉了，把它们解开一定更短。
        
- **3-opt**：切断三条边，重新连接。
    
    - _逻辑_：比 2-opt 搜索空间更大，能跳出一些简单的局部最优。
        

瓶颈：

无论做 2-opt 还是 3-opt，最终都会掉进局部最优 (Local Optima) 出不来。就像爬山爬到了一个小土包的顶端，四周都是下坡，但远处才是珠穆朗玛峰。

---

## 第二阶段：结构化时代 —— Lin-Kernighan (LK) 算法

**(The Era of Variable Depth Search)**

1973 年，Shen Lin 和 Brian Kernighan 提出了划时代的 **LK 算法**。它是 TSP 启发式算法的**分水岭**。

### 2.1 核心思想：变深度搜索 (Variable Depth Search)

之前的算法是定死的：要么切 2 条边，要么切 3 条。

LK 说：“为什么不让算法自己决定切几条边？”

LK 算法构造了一种复合动作，称为 **Ejection Chain (弹射链)**：

1. 断开边 $x_1$，连接边 $y_1$（此时变成一条非闭合路径）。
    
2. 为了闭合，被迫断开边 $x_2$，连接边 $y_2$。
    
3. ...
    
4. 这个过程可以一直持续下去 ($k$ 可以是 5, 10, 50...)，直到某一步，我们发现：“哎？如果现在把头尾连起来，总长度竟然比一开始短了！”
    

### 2.2 伟大之处

LK 算法不再局限于 $k=3$。它动态地根据图的拓扑结构，走出了一连串复杂的“连招”。

效果：它能从绝大多数局部最优中跳出来。在 70-90 年代，LK 是绝对的王者。

---

## 第三阶段：巅峰时代 —— LKH-1 与 LKH-2

**(The Era of Efficient Implementation & Candidate Sets)**

时间来到 2000 年，一位叫 **Keld Helsgaun** 的丹麦哥本哈根大学教授登场了。他把 LK 算法改写到了极致，命名为 **LKH (Lin-Kernighan-Helsgaun)**。

你可能会问：“只是改写代码，为什么能称神？”

因为 Helsgaun 引入了两个来自精确算法领域的智慧。

### 3.1 核心黑科技：$\alpha$-measure (候选集策略)

这是 LKH 碾压其他算法的根本原因。

- **问题**：在大规模 TSP（比如 10000 个点）中，LK 算法想做交换时，每一个点都有 9999 个邻居可选。尝试所有邻居太慢了。
    
- **Helsgaun 的洞见**：**不要瞎试！只试那些“大概率在最优解里”的边。**
    

他借用了我们上一章讲的 **Held-Karp 下界** 和 **1-Tree** 的概念：

1. 算出每个点的**对偶变量 $\pi$**（没错，就是列生成里的那个 $\pi$）。
    
2. 计算每条边的**灵敏度 (Sensitivity)**，即 $\alpha$-value。
    
    - $\alpha(i,j)$ 越小，说明这条边越重要，越可能属于最优解。
        
3. **Candidate Set**：对于每个点，只允许它和 $\alpha$ 值最小的 5 个点（Candidate）进行连接。
    

结果：搜索空间从 $N$ 缩减到了常数 $5$。速度提升了几个数量级，且精度几乎不掉。

这再次证明了：精确算法的理论（对偶性）是启发式算法的灯塔。

### 3.2 LKH-2：一般化 TSP

LKH-2 进一步优化了数据结构（使用 Splay Tree 管理路径翻转），并支持了非对称 TSP (ATSP) 等变种。至此，LKH-2 成为了学术界解决纯 TSP 问题的**标准 Benchmark**。如果你的新算法跑不过 LKH-2，那就发不了顶刊。

---

## 第四阶段：大一统时代 —— LKH-3

**(The Era of Generalization to VRP)**

2017 年左右，Helsgaun 发布了 **LKH-3**。这是一个里程碑式的扩展。

在此之前，LKH 只能解 TSP（一辆车，无约束）。

LKH-3 的目标是：万物皆可 TSP。它开始支持带有复杂约束的 VRP 问题。

### 4.1 核心思想：变换 (Transformation)

LKH-3 并没有针对 VRPTW 重写一套全新的 ALNS，而是极其巧妙地**把 VRP 伪装成了 TSP**。

- 多辆车怎么办？
    
    它在图中引入虚拟的“仓库复本” (Dummy Depots)。
    
    如果路径是 $0 \to A \to B \to 0 \to C \to D \to 0$（回了两次仓库，相当于两辆车）。
    
    LKH-3 把它看作一个超大的 TSP 环：$0_1 \to A \to B \to 0_2 \to C \to D \to 0_1$。
    
    通过调整虚拟仓库之间的距离（距离为 0），用解 TSP 的引擎去解多车问题。
    
- 时间窗和容量怎么办？
    
    LK 算法原本只看“距离”最短。
    
    LKH-3 修改了目标函数：
    
    $$Cost = \text{Distance} + M \times \text{Penalty}$$
    
    如果一条路径违反了时间窗，它的“长度”就会变得无穷大。
    
    LKH 的搜索引擎极其强大，它会自动避开这些高惩罚的路径，从而“自然演化”出满足时间窗的解。
    

### 4.2 LKH-3 的地位

目前，LKH-3 在许多 VRP 变种（CVRP, VRPTW, PDTSP）的标准算例上，依然保持着Best Known Solution (BKS) 的记录。

对于工业界来说，LKH-3 是一个现成的、极其强悍的黑盒求解器。

---

## 总结：从 2-opt 到 LKH-3 的逻辑链

|**阶段**|**算法**|**核心突破**|**解决了什么痛点**|
|---|---|---|---|
|**Stage 1**|**$k$-opt**|邻域交换 (Swap)|解决了“怎么动”的问题，但容易陷入局部最优。|
|**Stage 2**|**LK**|**变深度搜索 (Ejection Chains)**|解决了“怎么跳出局部最优”的问题，定义了最强的移动算子。|
|**Stage 3**|**LKH-1/2**|**$\alpha$-measure (灵敏度分析)**|解决了“大规模搜不动”的问题。利用精确算法理论指导搜索方向。|
|**Stage 4**|**LKH-3**|**问题转化 (Penalty Transformation)**|解决了“业务约束太复杂”的问题。把 VRPTW 降维打击成 TSP 来解。|

### 你的行动建议

既然你在研究运筹算法：

1. **必读论文**：Helsgaun, K. (2000). _An effective implementation of the Lin–Kernighan traveling salesman heuristic_. (理解 LKH 到底是怎么利用 $\pi$ 值的)。
    
2. **代码复现**：去下载 LKH-3 的 C 语言源码（开源的）。
    
    - 不要试图完全重写它（代码极其复杂）。
        
    - **重点看**：它是如何计算 `Candidate Set` 的，以及它是如何在 `Penalty` 函数中处理时间窗约束的。这对于你自己写 ALNS 极有借鉴意义。
        

至此，启发式算法的发展脉络也梳理清楚了。从单纯的**随机**，到**结构化**，再到利用**对偶理论**，最后**大一统**。

这套逻辑是否符合你对“技术进阶”的预期？

这是一个非常扎实且切中要害的问题。在启发式算法（尤其是 Local Search 和 Meta-heuristics）中，**算子 (Operators)** 是算法的“战术动作”。算法框架（如模拟退火、遗传算法、LKH）是“指挥官”，而算子是冲锋陷阵的“士兵”。

算子的演变路径，本质上是**从“盲目随机”到“利用拓扑结构”，再到“利用业务逻辑”**的过程。

我们将算子的演变分为四个代际来进行深度剖析。

---

### 第一代：点级操作 (Node-Based Operators)

时代背景： 早期朴素的局部搜索（Simple Local Search）。

核心逻辑： 把现在的解看作一串珠子，我一次只动一颗或两颗珠子。

#### 1. Relocate (点移位 / Insert)

- **动作：** 将节点 $i$ 从当前位置拔出来，插入到另一个位置 $j$ 之后。
    
- **复杂度：** $O(1)$ 的 Delta Evaluation（如果距离矩阵已知）。
    
- **效果：**
    
    - **优点：** 极其灵活，能微调路径顺序。
        
    - **缺点：** 破坏力太小。如果整个路径的大方向错了（比如顺时针走成了逆时针），靠 Relocate 一个个挪，哪怕挪到地老天荒也改不过来。
        

#### 2. Swap (点交换 / Exchange)

- **动作：** 交换节点 $i$ 和节点 $j$ 的位置。
    
- **效果：**
    
    - **优点：** 扰动比 Relocate 稍大。
        
    - **缺点：** 只能处理“点”层面的错误，无法处理“线”层面的纠缠。
        

---

### 第二代：边级与拓扑操作 (Edge-Based / Topological Operators)

**时代背景：** 人们发现 TSP 的核心难点在于**“消灭交叉”**。点级操作很难消除交叉，必须对“边”下手。这是 **2-opt** 诞生的背景。

#### 1. 2-opt (两条边交换)

这是运筹学历史上最经典的算子。

- **动作：** 选取两条不相邻的边 $(a, b)$ 和 $(c, d)$，断开它们。然后交叉连接：$a$ 连 $c$，$b$ 连 $d$。
    
- **几何本质：** 实际上是将 $b$ 到 $c$ 之间的这段路径进行了**翻转 (Reverse)**。
    
- **效果：** **专门用于消除路径的自交叉**。只要平面上有交叉，做一次 2-opt 必然能解开。它是 TSP 求解的“基本功”。
    

#### 2. Or-opt (链式移位)

由 Or 在 1976 年提出。

- **动作：** 它不是移动一个点，而是移动**连续的一串点**（比如连续 3 个点）到另一个位置。
    
- **演变逻辑：** 它是 Relocate 的升级版。
    
- **场景：** 在 VRP 中非常重要。因为有时候一段路径的方向是对的（比如顺路送了 A, B, C），只是这段路放错了车次。Or-opt 可以把整段逻辑保留下来搬家。
    

---

### 第三代：多车交互操作 (Inter-Route Operators)

时代背景： 从 TSP 转向 VRP (车辆路径问题)。

核心难点： 不仅要让单车的路最短，还要平衡多辆车之间的负载。必须打破“车与车”的界限。

#### 1. Cross / Crossover (交叉算子)

- **动作：** 选取两条路径（车 A 和 车 B）。把车 A 的后半段和车 B 的后半段互换。
    
- **效果：** 彻底改变两条路线的拓扑结构。类似于生物学中的染色体交叉。这对于优化车辆的终点归属非常有效。
    

#### 2. 2-opt* (Star 2-opt)

这是 2-opt 的跨路线版本。

- **动作：** 断开车 A 的一条边和车 B 的一条边，尝试交叉连接。
    
- **效果：** 它是 VRP 中最强的**局部搜索算子**之一，能有效减少车队总行驶距离。
    

---

### 第四代：破坏与重组 (Ruin & Recreate)

时代背景： LNS (Large Neighborhood Search) 和 ALNS (自适应大邻域搜索) 的兴起。

核心逻辑： 之前的算子都是“小修小补”（微创手术）。LNS 提倡“大破大立”（截肢手术）。既然局部调整跳不出局部最优，不如直接炸掉一半重修。

这一代的算子分为两类：**破坏算子 (Removal)** 和 **修复算子 (Insertion)**。

#### 1. 破坏算子 (Removal Operators)

- **Random Removal (随机移除)：** 瞎拆。为了增加随机性。
    
- **Worst Removal (最差移除)：** 谁成本高拆谁。比如某个点导致绕路很远，把它踢出来。
    
- **Shaw Removal (相关性移除) —— SOTA 级算子：**
    
    - **原理：** 这是 Patrick Shaw 提出的天才想法。如果要移除一组点，不要随机移，要移除**“相似”**的点。
        
    - **相似性定义：** 距离相近、时间窗相近、或者属于同一辆车。
        
    - **效果：** 移除了相似的点，修复时才有机会把它们“重新组合”到一起。这是 ALNS 算法性能强大的核心秘密。
        

#### 2. 修复算子 (Insertion Operators)

- **Greedy Insertion (贪婪插入)：** 把踢出来的点，一个个试，谁增加的成本最小就插哪里。
    
- **Regret Insertion (后悔/遗憾插入) —— SOTA 级算子：**
    
    - **原理：** 不看“现在插入有多便宜”，而是看**“如果现在不插，以后再插会贵多少”**（即后悔值）。
        
    - **计算：** 计算每个点在“最佳位置”和“次佳位置”的成本差值。差值越大，说明这个点“很挑剔”，必须优先安排。
        
    - **效果：** 极大地避免了贪婪算法的短视，是目前 VRP 求解的标准配置。
        

---

### 第五代：进化与混合 (Evolutionary & Hybrid)

**时代背景：** 遗传算法 (GA) 与 LKH 的结合。如何在保留两个父代优秀特征的前提下生成子代？

#### 1. EAX (Edge Assembly Crossover)

这是 Nagata 提出的，目前遗传算法解 TSP 的**最强算子**。

- **动作：** 它利用父代 A 和父代 B 的边组成一个个“AB-Cycle”，然后通过复杂的逻辑删除中间的边，生成子代。
    
- **效果：** 它能完美地继承父代的优良结构（Edge Preservation），同时引入极高质量的变异。搭载 EAX 的遗传算法，在纯 TSP 问题上甚至可以挑战 LKH。
    

---

### 总结：算子演变图谱

|**代际**|**代表算子**|**操作对象**|**核心哲学**|**工业界地位**|
|---|---|---|---|---|
|**第一代**|Relocate, Swap|**点 (Node)**|微调，修补|基础组件，至今必用|
|**第二代**|**2-opt**, Or-opt|**边/链 (Edge)**|**解开死结 (Uncrossing)**|**TSP 的灵魂**，必须实现|
|**第三代**|Cross, 2-opt*|**多路径 (Routes)**|车辆间负载均衡|VRP 必用|
|**第四代**|**Shaw Removal**, **Regret Insertion**|**子结构 (Sub-structure)**|**大破大立 (Global Jump)**|**ALNS 的核心**，目前解 VRP 最主流的配置|
|**第五代**|EAX, LKH-Kicks|**特征 (Features)**|结构重组与对偶指导|追求极致解质量时使用|

给你的建议：

如果你正在写一个 VRPTW 的求解器（比如基于 ALNS）：

1. **必须实现：** 2-opt (用于单车路径优化), Regret Insertion (用于构造解), Shaw Removal (用于跳出局部最优)。
    
2. **锦上添花：** Or-opt (处理时间窗非常有效)。
    
3. **不要浪费时间：** 除非你是做纯学术研究，否则不要一开始就去写复杂的 EAX，性价比不高。
    

这个算子的族谱，是否让你对“如何改动一个解”有了更具体的画面？