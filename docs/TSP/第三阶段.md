这是为您精心编撰的《运筹学精确算法专题》第三章节。

本章节将采用**严谨的数学定义**与**逻辑推导**，系统讲解 **Branch-and-Price (分支定价)** 及其核心组件 **Dantzig-Wolfe 分解**。我们将以 TSP 为载体，通过这一章节揭示运筹学中“Held-Karp 下界”的数学本质。

---

# 运筹学精确算法专题三：分支定价与 Held-Karp 下界

**Topic 3: Branch-and-Price & Dantzig-Wolfe Decomposition**

## 1. 问题的重构：从边的约束到树的结构 (Problem Reformulation)

在 Branch-and-Cut 中，我们关注的是如何通过切割平面来修复“连通性”。而在 Branch-and-Price 中，我们采用反向思维：

我们保留“连通性”（通过选择特定的图结构），转而将“度数约束”松弛化，交由主问题处理。

### 1.1 核心定义：1-Tree (1-树)

为了实施分解，必须引入 TSP 中的核心子结构——**1-Tree**。

定义 1.1 (1-Tree):

给定图 $G=(V, E)$，其中节点 $1$ 为特定节点（如 Depot）。一个子图 $T$ 被称为 1-Tree，当且仅当：

1. 在节点集合 $V \setminus \{1\}$ 上，其边构成一棵**生成树 (Spanning Tree)**。
    
2. 节点 $1$ 恰好连接两条边到 $V \setminus \{1\}$ 中。
    

**性质：**

- **边数性质：** 1-Tree 恰好包含 $|V|$ 条边。
    
- **连通性：** 1-Tree 包含且仅包含一个环（Cycle）。
    
- **与 TSP 的关系：** 每一个合法的 TSP 巡回（Tour）都是一个 1-Tree，且是一个**每个节点度数均为 2** 的特殊 1-Tree。
    

---

## 2. Dantzig-Wolfe 分解 (The Decomposition)

我们将 TSP 问题分解为两部分：

- **子问题 (Subproblem)**：生成 1-Tree（天然满足连通性和部分结构，但不满足度数约束）。
    
- **主问题 (Master Problem)**：通过凸组合（Convex Combination）混合多个 1-Tree，使得所有节点的**平均度数**等于 2。
    

### 2.1 原始变量与分解变量的映射

设 $K$ 为图中所有可能存在的 1-Tree 的集合（虽然 $|K|$ 是指数级的，但理论存在）。

- $T_k$：第 $k$ 个 1-Tree。
    
- $c_k$：$T_k$ 的总成本。
    
- $d_{ik}$：在 $T_k$ 中，节点 $i$ 的度数（可能是 1, 2, 3...）。
    

我们将原始决策变量 $x_{ij}$ 表示为 1-Tree 的加权组合：

$$x_{ij} = \sum_{k \in K} \mathbb{I}_{ij}^k \lambda_k$$

其中 $\mathbb{I}_{ij}^k$ 为指示函数（若边 $(i,j)$ 在 $T_k$ 中则为 1），$\lambda_k$ 为权重。

### 2.2 限制性主问题 (Restricted Master Problem, RMP)

我们构建如下线性规划模型：

$$\begin{aligned} \textbf{Min} \quad & Z = \sum_{k \in K'} c_k \lambda_k \\ \textbf{s.t.} \quad & \sum_{k \in K'} d_{ik} \lambda_k = 2, \quad \forall i \in V \quad [\pi_i] \\ & \sum_{k \in K'} \lambda_k = 1 \quad [\mu] \\ & \lambda_k \ge 0 \end{aligned}$$

- $K' \subset K$：当前已生成的 1-Tree 子集。
    
- **约束 (1)**：度数约束。要求所有被选中的 1-Tree 的加权平均度数，对于每个节点 $i$ 都必须等于 2。对偶变量为 $\pi_i$。
    
- **约束 (2)**：凸组合约束。权重之和为 1。对偶变量为 $\mu$。
    

---

## 3. 列生成机制 (Column Generation)

由于 $|K|$ 极其巨大，我们无法直接求解完全的主问题。我们需要通过**定价子问题 (Pricing Subproblem)** 动态生成能够优化目标函数的列（即新的 1-Tree）。

### 3.1 检验数推导 (Reduced Cost Derivation)

根据线性规划理论，我们需要寻找一个变量 $\lambda_k$，使其检验数 (Reduced Cost) $\bar{c}_k < 0$。

检验数公式为：

$$\bar{c}_k = c_k - \sum_{i \in V} \pi_i d_{ik} - \mu$$

将 $c_k = \sum_{e \in T_k} c_e$ 和 $d_{ik} = \sum_{e \in T_k, e \in \delta(i)} 1$ 代入上式：

$$\bar{c}_k = \sum_{(i,j) \in T_k} c_{ij} - \sum_{i \in V} \pi_i (\sum_{(i,j) \in T_k, i \in e} 1) - \mu$$

经过整理（每条边 $(i,j)$ 连接了 $i$ 和 $j$，因此会减去 $\pi_i$ 和 $\pi_j$）：

$$\bar{c}_k = \sum_{(i,j) \in T_k} (c_{ij} - \pi_i - \pi_j) - \mu$$

### 3.2 定价子问题模型

为了最小化 $\bar{c}_k$，我们忽略常数 $\mu$，问题等价于求解：

在新的边权体系下，寻找一个总权重最小的 1-Tree。

定义新边权：

$$\tilde{c}_{ij} = c_{ij} - \pi_i - \pi_j$$

**子问题算法 (Solving the Pricing Problem):**

1. **更新权重**：利用主问题传递的 $\pi$，计算全图所有边的 $\tilde{c}_{ij}$。
    
2. **求解 MST**：在节点集合 $V \setminus \{1\}$ 上，使用 Prim 或 Kruskal 算法求解基于 $\tilde{c}$ 的最小生成树。
    
3. **连接根节点**：找到连接节点 $1$ 的两条 $\tilde{c}$ 最小的边，加入 MST。
    
4. **输出**：若该 1-Tree 的计算成本 $< \mu$，则 $\bar{c}_k < 0$，将其加入 RMP；否则，当前解已达到最优。
    

---

## 4. 算法全流程与物理意义 (Algorithm & Interpretation)

### 4.1 算法流程

1. **初始化**：生成若干个简单的 1-Tree 构成初始 $K'$（可使用大 M 法保证可行性）。
    
2. **求解 RMP**：求解线性规划，得到最优解 $\lambda^*$ 和对偶解 $\pi^*$。
    
3. **定价**：利用 $\pi^*$ 更新边权，求解最小 1-Tree。
    
4. **收敛判定**：
    
    - 若 $\bar{c}_{min} < 0$：将新生成的 1-Tree 列加入 RMP，转步骤 2。
        
    - 若 $\bar{c}_{min} \ge 0$：列生成结束。此时 RMP 的目标函数值 $Z_{LP}$ 即为 **Held-Karp 下界**。
        

### 4.2 物理意义：拉格朗日松弛

上述过程在数学上等价于求解 Lagrangian Dual Problem。

$\pi_i$ 可以被视为对“度数违规”的惩罚因子（Lagrangian Multipliers）。

- 若某节点度数 $>2$，$\pi_i$ 增大，导致 $\tilde{c}_{ij}$ 减小（吸引更多边连接？不，注意公式是 $c - \pi$。若 $\pi$ 增大，$\tilde{c}$ 减小，倾向于选该边... 等等，让我们严谨推导）。
    

严谨修正：

注意 RMP 约束方向 $\sum d_{ik}\lambda_k = 2$。

在最小化问题中，若 $\sum d_{ik}\lambda_k > 2$（度数过剩），且 $\pi_i$ 为对应等式约束对偶变量。

根据对偶理论，若我们要惩罚过高的度数，应使得包含 $i$ 的边成本变高。

但在 Reduced Cost 定义 $\bar{c} = c - \pi^T A$ 中，若 $\pi_i$ 为正且很大，$\tilde{c}_{ij} = c_{ij} - \pi_i - \pi_j$ 会变小。

这似乎意味着 $\pi_i$ 越大，边权越小，越容易被选中，度数会更高？

这里的符号依赖于具体的对偶定义方向。

在标准的 Held-Karp 迭代中（次梯度法），我们通常最大化下界：

$$\max_{\pi} \min_{T} \sum_{(i,j) \in T} (c_{ij} + \pi_i + \pi_j) - 2\sum \pi_i$$

这与列生成是对偶互补的。在列生成中，求解器会自动调整 $\pi$ 的符号以达到平衡。

---

## 5. 分支 (The "Branch" in B&P)

当列生成收敛时，主问题解 $\lambda^*$ 往往是小数。例如：

$$\lambda_1 = 0.5 (T_1) + \lambda_2 = 0.5 (T_2)$$

这意味着我们得到的是两个树的“叠加态”，而非一条确定的路径。此时需要分支。

分支策略：

不建议直接对 $\lambda$ 分支（即 $T_1$ 选或不选），这会破坏子结构。

标准做法是在原始边 $x_{ij}$ 上分支：

1. 计算当前叠加态中每条边的流量 $x^*_{ij} = \sum \mathbb{I}_{ij}^k \lambda_k$。
    
2. 选择一个 $x^*_{ij}$ 接近 0.5 的边。
    
3. **分支节点 1 ($x_{ij} = 0$)**：
    
    - **主问题**：去除所有包含边 $(i,j)$ 的列。
        
    - **子问题**：将边 $(i,j)$ 的成本设为 $+\infty$（禁止选中）。
        
4. **分支节点 2 ($x_{ij} = 1$)**：
    
    - **主问题**：去除所有**不**包含边 $(i,j)$ 的列（或者强行约束）。
        
    - **子问题**：强制连接 $(i,j)$（例如将其边权设为 $-\infty$，或在 MST 中缩点）。
        

---

## 6. 总结 (Conclusion)

Branch-and-Price 将 TSP 问题转化为在一个凸包内寻找最优组合的问题。

- **优点**：它生成的 **Held-Karp 下界** 极其紧致，通常优于 MTZ 模型和简单的割平面法。它证明了 TSP 的多面体可以通过 1-Tree 多面体的交集来逼近。
    
- **难点**：在于子问题（Pricing）必须能高效求解。对于 TSP，MST 是多项式时间的，因此 B&P 非常有效。但对于 VRPTW，子问题变成了 NP-Hard 的 ESPPRC，这也是为什么 VRP 求解器比 TSP 求解器更难开发的原因。
    

思考题：

如果我们将子问题从 1-Tree 换成简单的“2-匹配 (2-Matching)”（即只要求度数为2，允许有子回路），主问题和对偶变量的物理含义会发生什么变化？这将引导你走向 Fenchel 切割等更深奥的领域。

这两个问题都非常核心。第一个关于 $x$ 和 $\lambda$ 的关系，是理解**Dantzig-Wolfe 分解**物理意义的关键；第二个关于**检验数（Reduced Cost）**的推导，是理解**列生成**算法运行机制的钥匙。

我们一个一个拆开来讲。

---

### 第一部分：$x_{ij}$ 与 $\lambda_k$ 的关系 —— “图层的叠加”

你问得好：“$\lambda_k$ 不是比例吗？那个公式是什么意思？”

我们可以用**PhotoShop 图层叠加**或者**调色盘**来理解。

- **$\lambda_k$ (比例/透明度)**：你手里有几张做好的透明底片（1-Tree），$\lambda$ 决定了你要把这张底片以多大的“透明度”叠加上去。
    
- **$\mathbb{I}_{ij}^k$ (底片内容)**：这是一张具体的底片 $T_k$。如果这张底片上画了边 $(i,j)$，这个值为 1，否则为 0。
    
- **$x_{ij}$ (最终画面)**：这是所有底片叠加后，我们看到的最终结果（每条边的颜色深浅）。
    

#### 举个具体的数字例子

假设我们有 4 个城市：A, B, C, D。

我们在主问题里选中了 2 个不同的 1-Tree（记为 $T_1$ 和 $T_2$），并且求解器告诉我们要以 0.5 : 0.5 的比例混合它们（即 $\lambda_1 = 0.5, \lambda_2 = 0.5$）。

底片 1 ($T_1$) 的结构：

这是一个环：$A \to B \to C \to D \to A$。

- 包含边：$(A,B), (B,C), (C,D), (D,A)$。
    
- $\mathbb{I}_{AB}^1 = 1, \mathbb{I}_{BC}^1 = 1, ...$ 其他边为 0。
    

底片 2 ($T_2$) 的结构：

这是一个蝴蝶结形状：$A \to C \to B \to D \to A$。

- 包含边：$(A,C), (C,B), (B,D), (D,A)$。
    
- $\mathbb{I}_{AC}^2 = 1, \mathbb{I}_{CB}^2 = 1, ...$ 其他边为 0。
    

**现在进行叠加计算 ($x_{ij} = \sum \mathbb{I}_{ij}^k \lambda_k$)：**

1. **看边 $(A, B)$**：
    
    - $T_1$ 里有这条边 (1)；$T_2$ 里没有 (0)。
        
    - $x_{AB} = 1 \times 0.5 + 0 \times 0.5 = \mathbf{0.5}$
        
    - _物理含义：这条路只有一半的几率被选中。_
        
2. **看边 $(D, A)$**：
    
    - $T_1$ 里有 (1)；$T_2$ 里也有 (1)。
        
    - $x_{DA} = 1 \times 0.5 + 1 \times 0.5 = \mathbf{1.0}$
        
    - _物理含义：不管选哪个方案，这条路都要走，所以它是确定的。_
        
3. **看边 $(A, C)$**：
    
    - $T_1$ 里没有 (0)；$T_2$ 里有 (1)。
        
    - $x_{AC} = 0 \times 0.5 + 1 \times 0.5 = \mathbf{0.5}$
        

**总结：** 这个公式就是把**“宏观的方案选择”**（$\lambda$）翻译回**“微观的边流量”**（$x$）。在分支定价的最后一步（分支），我们需要基于这个 $x$ 值（比如 0.5）去进行分支，所以这个转换至关重要。

---

### 第二部分：检验数 $\bar{c}_k$ 的推导 —— 为什么 $\pi$ 会跑到边权里去？

这个推导困扰你的是如何把**节点的度数**（$d_{ik}$）转化成**边的求和**。这是一步关键的代数变形。

#### 1. 检验数的原始定义

在线性规划中，对于主问题的一个变量 $\lambda_k$（代表第 $k$ 个 1-Tree），它的检验数公式是：

$$\text{Reduced Cost} = (\text{该列原本的成本}) - (\text{该列在约束中的贡献} \times \text{对偶价格})$$

对应到我们的模型：

- 成本：$c_k$ （第 $k$ 个树的总边权）
    
- 约束：$\sum_{k} d_{ik} \lambda_k = 2$ （针对每个节点 $i$ 都有一个约束）
    
- 对偶变量：$\pi_i$ （对应节点 $i$ 的约束）
    

所以公式写出来是：

$$\bar{c}_k = c_k - \sum_{i \in V} (\pi_i \times d_{ik}) - \mu$$

(注：$\mu$ 是 $\sum \lambda = 1$ 的对偶，是常数，我们先不管它)

#### 2. 关键难点：如何理解 $\sum_{i} \pi_i d_{ik}$ ？

这一项的意思是：**计算这棵树 $T_k$ 在所有节点上产生的“度数罚款”总和。**

我们来换个角度算这笔账：**按边来算，而不是按点算。**

假设树 $T_k$ 里有一条边 $(u, v)$。

- 这条边连在节点 $u$ 上 $\rightarrow$ 它给节点 $u$ 的度数贡献了 1 $\rightarrow$ 产生罚款 $1 \times \pi_u$。
    
- 这条边连在节点 $v$ 上 $\rightarrow$ 它给节点 $v$ 的度数贡献了 1 $\rightarrow$ 产生罚款 $1 \times \pi_v$。
    

**结论：** 树里的**每一条边** $(u, v)$，实际上都贡献了 $\pi_u + \pi_v$ 这么多罚款。

所以，我们可以把求和符号从“对点求和”变成“对边求和”：

$$\sum_{i \in V} \pi_i d_{ik} = \sum_{(u,v) \in T_k} (\pi_u + \pi_v)$$

#### 3. 最终代入推导

现在把上面的结论代回原始公式。

$$\begin{aligned} \bar{c}_k &= c_k - \sum_{i \in V} \pi_i d_{ik} \\ &= \left( \sum_{(u,v) \in T_k} c_{uv} \right) - \left( \sum_{(u,v) \in T_k} (\pi_u + \pi_v) \right) \quad \text{(把整棵树拆成边)} \\ &= \sum_{(u,v) \in T_k} \left( c_{uv} - (\pi_u + \pi_v) \right) \quad \text{(合并同类项)} \end{aligned}$$

#### 4. 物理意义大揭秘

看到最后这一步了吗？

$$\sum_{(u,v) \in T_k} (c_{uv} - \pi_u - \pi_v)$$

这意味着，我们要找一个检验数最小的树，其实就是找一个树，它的边权之和最小。但是！边的权重不再是原始的距离 $c_{uv}$，而是被修改后的权重：

$$\tilde{c}_{uv} = c_{uv} - \pi_u - \pi_v$$

这就解释了列生成的核心逻辑：

主问题通过 $\pi$ 告诉子问题：“我觉得 $u$ 和 $v$ 的度数太小了（$\pi$ 为负），你去连它们吧！”

$\rightarrow$ $\pi_u, \pi_v$ 为负

$\rightarrow$ $-\pi_u$ 变为正

$\rightarrow$ 新边权 $\tilde{c}_{uv}$ 变大？

**等一下，这里的正负号逻辑要非常小心（这是最容易晕的地方）：**

- 如果是 $\sum d \lambda = 2$ 且**最小化**问题：
    
    - 若某点度数**过剩**（$>2$），求解器希望减少连接，$\pi$ 会变**大**（正数）。
        
    - 代入 $c - \pi$ 公式，新边权 $\tilde{c}$ 变**小**。
        
    - MST 算法倾向于选边权小的边。
        
    - **哎？** 边权变小 $\rightarrow$ 容易被选中 $\rightarrow$ 度数变得更大？这不就死循环了吗？
        

这里的逻辑修正（非常重要）：

Reduced Cost 的目的是寻找能改善当前解的新列。

- 如果 $\pi_i$ 很大（说明主问题觉得点 $i$ 太“拥挤”，度数太高），那么 $\tilde{c}_{uv} = c_{uv} - \pi_u - \pi_v$ 会变得很小（甚至负无穷）。
    
- MST 算法会**疯狂地**把这条边选进来。
    
- 这似乎是反直觉的？其实是因为 Held-Karp 下界的迭代通常是**最大化**问题，而列生成是**最小化**问题。
    
    - 在列生成中，如果 $\pi_i$ 很大，意味着该点的**约束极紧**（Resource is valuable）。
        
    - Reduced Cost 为负意味着：这条路径的成本 $c$ **小于** 它所能提供的价值 $\pi$。
        
    - 所以我们要选它。
        

简单的记忆法：

不要纠结 $\pi$ 的正负，求解器会自动调整。你只需要记住推导结果：

子问题就是在跑最小生成树，只是每条边的长度，被两端的“过路费”($\pi$) 给减掉了。

这样这两个问题讲通了吗？